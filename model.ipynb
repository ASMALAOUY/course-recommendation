{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd233be-1611-47f4-8351-999e960f9664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== ÉTAPE 1 : Dataset chargé ===================\n",
      "Taille du dataset (lignes, colonnes) : (13608, 20)\n",
      "\n",
      "Aperçu des 5 premières lignes :\n",
      "        id                                              title\n",
      "0   762616  The Complete SQL Bootcamp 2020: Go from Zero t...\n",
      "1   937678  Tableau 2020 A-Z: Hands-On Tableau Training fo...\n",
      "2  1361790             PMP Exam Prep Seminar -  PMBOK Guide 6\n",
      "3   648826         The Complete Financial Analyst Course 2020\n",
      "4   637930  An Entire MBA in 1 Course:Award Winning Busine...\n",
      "\n",
      "Types des colonnes :\n",
      "id                                int64\n",
      "title                            object\n",
      "url                              object\n",
      "is_paid                            bool\n",
      "num_subscribers                   int64\n",
      "avg_rating                      float64\n",
      "avg_rating_recent               float64\n",
      "rating                          float64\n",
      "num_reviews                       int64\n",
      "is_wishlisted                      bool\n",
      "num_published_lectures            int64\n",
      "num_published_practice_tests      int64\n",
      "created                          object\n",
      "published_time                   object\n",
      "discount_price__amount          float64\n",
      "discount_price__currency         object\n",
      "discount_price__price_string     object\n",
      "price_detail__amount            float64\n",
      "price_detail__currency           object\n",
      "price_detail__price_string       object\n",
      "dtype: object\n",
      "================================================================\n",
      "\n",
      "=================== ÉTAPE 2 : Vérification de la colonne ID ===================\n",
      "Type de la colonne id : int64\n",
      "Quelques id : [762616, 937678, 1361790, 648826, 637930]\n",
      "================================================================\n",
      "\n",
      "=================== ÉTAPE 3 : Nettoyage NLP ===================\n",
      "Aperçu avant / après nettoyage :\n",
      "                                               title  \\\n",
      "0  The Complete SQL Bootcamp 2020: Go from Zero t...   \n",
      "1  Tableau 2020 A-Z: Hands-On Tableau Training fo...   \n",
      "2             PMP Exam Prep Seminar -  PMBOK Guide 6   \n",
      "3         The Complete Financial Analyst Course 2020   \n",
      "4  An Entire MBA in 1 Course:Award Winning Busine...   \n",
      "5  Microsoft Power BI - A Complete Introduction [...   \n",
      "6  Agile Crash Course: Agile Project Management; ...   \n",
      "7  Beginner to Pro in Excel: Financial Modeling a...   \n",
      "8  Become a Product Manager | Learn the Skills & ...   \n",
      "9      The Business Intelligence Analyst Course 2020   \n",
      "\n",
      "                                         clean_title  \n",
      "0                    complete sql bootcamp zero hero  \n",
      "1      tableau z hands tableau training data science  \n",
      "2                  pmp exam prep seminar pmbok guide  \n",
      "3                  complete financial analyst course  \n",
      "4  entire mba course award winning business schoo...  \n",
      "5   microsoft power bi complete introduction edition  \n",
      "6  agile crash course agile project management ag...  \n",
      "7    beginner pro excel financial modeling valuation  \n",
      "8                   product manager learn skills job  \n",
      "9               business intelligence analyst course  \n",
      "================================================================\n",
      "\n",
      "=================== ÉTAPE 4 : TF-IDF ===================\n",
      "Taille de la matrice TF-IDF : (13608, 8149)\n",
      "Nombre de cours      : 13608\n",
      "Taille du vocabulaire: 8149\n",
      "\n",
      "Exemples de mots du vocabulaire TF-IDF :\n",
      "['aa' 'aace' 'aalssc' 'aangifte' 'ab' 'aba' 'abandon' 'abc' 'abertura'\n",
      " 'abnormally' 'abra' 'abroad' 'absenteeism' 'absolute' 'abstract' 'abu'\n",
      " 'abundance' 'abundancia' 'ac' 'aca' 'acabando' 'acabar' 'acabou'\n",
      " 'academia' 'academic' 'academy' 'acca' 'accaclasses' 'accelerate'\n",
      " 'accelerated']\n",
      "================================================================\n",
      "\n",
      "=================== MODEL.PY CHARGÉ AVEC SUCCÈS ===================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model.py\n",
    "# ---------------------------\n",
    "# Chargement du dataset + préparation NLP + TF-IDF\n",
    "# Utilisé par recommender.py et app.py\n",
    "# ---------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "# ============================================================\n",
    "# 1) Charger le dataset\n",
    "# ============================================================\n",
    "\n",
    "# IMPORTANT : adapte ce chemin selon l'endroit où se trouve ton fichier\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\pc\\\\Desktop\\\\course-recommendation\\\\data\\\\courses.csv\")\n",
    "\n",
    "# Supprimer lignes sans titre (sécurité)\n",
    "df = df.dropna(subset=[\"title\"]).copy()\n",
    "\n",
    "print(\"\\n=================== ÉTAPE 1 : Dataset chargé ===================\")\n",
    "print(\"Taille du dataset (lignes, colonnes) :\", df.shape)\n",
    "print(\"\\nAperçu des 5 premières lignes :\")\n",
    "print(df[[\"id\", \"title\"]].head())\n",
    "print(\"\\nTypes des colonnes :\")\n",
    "print(df.dtypes)\n",
    "print(\"================================================================\\n\")\n",
    "\n",
    "# Vérification / conversion de l'ID\n",
    "if df[\"id\"].dtype != \"int64\" and df[\"id\"].dtype != \"int32\":\n",
    "    df[\"id\"] = df[\"id\"].astype(int)\n",
    "\n",
    "print(\"=================== ÉTAPE 2 : Vérification de la colonne ID ===================\")\n",
    "print(\"Type de la colonne id :\", df[\"id\"].dtype)\n",
    "print(\"Quelques id :\", df[\"id\"].head().tolist())\n",
    "print(\"================================================================\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Fonction de nettoyage (NLP simple)\n",
    "# ============================================================\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Nettoyage simple du titre :\n",
    "    - minuscules\n",
    "    - suppression de la ponctuation / chiffres\n",
    "    - suppression des stopwords anglais\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in ENGLISH_STOP_WORDS]\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "# Appliquer le nettoyage\n",
    "df[\"clean_title\"] = df[\"title\"].apply(clean_text)\n",
    "\n",
    "print(\"=================== ÉTAPE 3 : Nettoyage NLP ===================\")\n",
    "print(\"Aperçu avant / après nettoyage :\")\n",
    "print(df[[\"title\", \"clean_title\"]].head(10))\n",
    "print(\"================================================================\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Vectorisation TF-IDF\n",
    "# ============================================================\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Entraîner TF-IDF sur le texte nettoyé\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"clean_title\"])\n",
    "\n",
    "print(\"=================== ÉTAPE 4 : TF-IDF ===================\")\n",
    "print(\"Taille de la matrice TF-IDF :\", tfidf_matrix.shape)\n",
    "print(\"Nombre de cours      :\", tfidf_matrix.shape[0])\n",
    "print(\"Taille du vocabulaire:\", tfidf_matrix.shape[1])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"\\nExemples de mots du vocabulaire TF-IDF :\")\n",
    "print(feature_names[:30])\n",
    "print(\"================================================================\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Vectorisation d'un texte externe (optionnel)\n",
    "# ============================================================\n",
    "\n",
    "def vectorize_text(text: str):\n",
    "    clean = clean_text(text)\n",
    "    return vectorizer.transform([clean])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Exposé aux autres fichiers :\n",
    "# - df : DataFrame des cours\n",
    "# - tfidf_matrix : matrice TF-IDF\n",
    "# - vectorizer : modèle TF-IDF\n",
    "# - clean_text(), vectorize_text() : utilitaires NLP\n",
    "# ============================================================\n",
    "\n",
    "print(\"=================== MODEL.PY CHARGÉ AVEC SUCCÈS ===================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f175760a-6ea4-4d5f-a9bf-7bcd677b6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"model\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b02d3008-8ecb-4acf-a66d-a813c3712053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡ Sauvegarde des fichiers du modèle...\n",
      "✅ Sauvegarde terminée : fichiers prêts pour la recommandation !\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "print(\"➡ Sauvegarde des fichiers du modèle...\")\n",
    "\n",
    "joblib.dump(df, \"model/courses_df.pkl\")\n",
    "joblib.dump(vectorizer, \"model/tfidf_vectorizer.pkl\")\n",
    "joblib.dump(tfidf_matrix, \"model/tfidf_matrix.pkl\")\n",
    "\n",
    "print(\"✅ Sauvegarde terminée : fichiers prêts pour la recommandation !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac4301-3250-4d0b-a643-dedc9990c2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
